{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7915aab4-5560-4838-8756-f682b23f3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer,\n",
    "    CountVectorizer\n",
    ")\n",
    "from sklearn.decomposition import (\n",
    "    NMF,\n",
    "    LatentDirichletAllocation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "125bf421-f205-4068-8bb1-cd86080771c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 100\n",
    "no_topics = 5\n",
    "no_top_words = 10\n",
    "docsdir = \"../arxiv_papers_infos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a659217b-6dce-41f6-a993-681a6e4170a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(f\"{docsdir}/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2ec86037-f11a-4735-bac7-7d0d039438f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for filename in filenames:\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = f\"{data['result']['title']} -- {data['result']['abstract']}\"\n",
    "    documents.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e61bd799-912d-4196-9a74-0f2edcb667b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronnypetson/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95,\n",
    "    min_df=2,\n",
    "    max_features=no_features,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e38d9653-4fd9-460e-a5a6-52c8de424edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4263968-909a-48dc-aeda-ce94b6c615b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab1c1173-8ccd-4987-bbb7-edc53e2daa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsne():\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        learning_rate='auto',\n",
    "        init='random',\n",
    "        perplexity=3\n",
    "    )\n",
    "    return tsne\n",
    "\n",
    "def plot(X):\n",
    "    plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf4caddf-d063-49a6-9696-7927678dc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = get_tsne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ae43678-2d38-46c7-922b-bf48a2347421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "574cb827-7d2b-4bcb-9613-29612a81006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_tsne[:, 0], X_tsne[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c5f031db-7e18-4922-813f-cc6a055fcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_idx = 4\n",
    "dists = np.linalg.norm(X_tsne[src_idx] - X_tsne, axis=1)\n",
    "sim_ids = np.argsort(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dd99fc99-e485-4f3d-a55b-14d97b1ae20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-task deep cnn model for no-reference image quality assessment on smartphone camera photos \n",
      "\n",
      "ams_adrn at semeval-2022 task 5: a suitable image-text multimodal joint modeling method for multi-task misogyny identification \n",
      "\n",
      "upb at semeval-2022 task 5: enhancing uniter with image sentiment and graph convolutional networks for multimedia automatic misogyny identification \n",
      "\n",
      "generating fact checking explanations \n",
      "\n",
      "nlp-cuet@dravidianlangtech-eacl2021: investigating visual and textual features to identify trolls from multimodal social media memes \n",
      "\n",
      "identification of social-media platform of videos through the use of shared features \n",
      "\n",
      "similarity learning for authorship verification in social media \n",
      "\n",
      "question retrieval for community-based question answering via heterogeneous network integration learning \n",
      "\n",
      "short text topic modeling: application to tweets about bitcoin \n",
      "\n",
      "sexism prediction in spanish and english tweets using monolingual and multilingual bert and ensemble models \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(documents[sim_ids[idx]].split(\"--\")[0], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1583a533-bfe4-496e-a40f-0cdd12aa92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(\n",
    "    max_df=0.95,\n",
    "    min_df=2,\n",
    "    max_features=no_features,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2bb101f-4a58-48e8-8ed3-2f62017fab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronnypetson/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1425: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Run NMF\n",
    "nmf = NMF(\n",
    "    n_components=no_topics,\n",
    "    random_state=1,\n",
    "    alpha=.1,\n",
    "    l1_ratio=.5,\n",
    "    init='nndsvd'\n",
    ").fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6592e332-3545-42fc-89e2-c1f2b6219ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=no_topics,\n",
    "    max_iter=5,\n",
    "    learning_method='online',\n",
    "    learning_offset=50.,\n",
    "    random_state=0\n",
    ").fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6dae10a3-9757-4bd2-a62c-cdc75146f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join(\n",
    "                [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "            )\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3271d982-fa18-4b63-af75-81f8a9169508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "learning data detection media neural deep text models based task\n",
      "Topic 1:\n",
      "network networks influence diffusion model nodes information dynamics spreading spread\n",
      "Topic 2:\n",
      "users user twitter online content media information political platforms tweets\n",
      "Topic 3:\n",
      "news fake detection information media spread political content features twitter\n",
      "Topic 4:\n",
      "covid 19 spread people public tweets analysis related sentiment data\n",
      "\n",
      "Topic 0:\n",
      "data learning media model based neural models network deep text\n",
      "Topic 1:\n",
      "news detection graph fake information media based networks network content\n",
      "Topic 2:\n",
      "media twitter data analysis network political opinion study information online\n",
      "Topic 3:\n",
      "users user content online 19 covid images networks network based\n",
      "Topic 4:\n",
      "network networks model information influence diffusion problem nodes spread based\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6625936-9c28-4e03-8539-50241c9088f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
