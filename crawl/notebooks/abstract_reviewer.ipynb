{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "source_dir = os.path.join(\"..\", \"arxiv_papers_infos\")\n",
    "papers_paths = glob(os.path.join(source_dir, \"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "paper_data = []\n",
    "for path in papers_paths:\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    paper_data.append(data)\n",
    "abstracts = [data[\"result\"][\"abstract\"] for data in paper_data]\n",
    "titles = [data[\"result\"][\"title\"] for data in paper_data]\n",
    "urls = []\n",
    "for data in paper_data:\n",
    "    url = \"_\".join(data[\"result\"][\"arxiv_id\"].split(\"/\"))\n",
    "    url = f\"https://arxiv.org/pdf/{url}.pdf\"\n",
    "    urls.append(url)\n",
    "print(len(paper_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "api_key_path = os.path.join(\n",
    "    \"C:\\\\Users\", \"DXT6\", \"OneDrive - PETROBRAS\",\n",
    "    \"CENPES\", \"TEO\", \"keys\", \"OpenAI\", \"apikey.txt\"\n",
    ")\n",
    "\n",
    "with open(api_key_path, \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt for question #1\n",
    "prompt = \"\"\"\n",
    "Regarding the paper available at {url} , answer the following question. Multiple options can be correct. Try to be as precise as you can, but it's ok to admit if you don't know.\n",
    "\n",
    "In the presented neural network, what can change during inference? Justify.\n",
    "(a) The network function composition or the selective activation of parts of the network.\n",
    "Between other things, this includes early-exits, conditional computing, and the cases where a recurrent neural net (e.g. RNN, LSTM, GRU) runs a variable number of steps.\n",
    "(b) Network weights are generated (except quantization).\n",
    "(c) Quantization (or change in precision) of weights or feature maps.\n",
    "(d) None of the above or not mentioned.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big-little adaptive neural networks on low-power near-subthreshold processors\n",
      "\n",
      "this paper investigates the energy savings that near-subthreshold processors can obtain in edge ai applications and proposes strategies to improve them while maintaining the accuracy of the application. the selected processors deploy adaptive voltage scaling techniques in which the frequency and voltage levels of the processor core are determined at the run-time. in these systems, embedded ram and flash memory size is typically limited to less than 1 megabyte to save power. this limited memory imposes restrictions on the complexity of the neural networks model that can be mapped to these devices and the required trade-offs between accuracy and battery life. to address these issues, we propose and evaluate alternative 'big-little' neural network strategies to improve battery life while maintaining prediction accuracy. the strategies are applied to a human activity recognition application selected as a demonstrator that shows that compared to the original network, the best configurations obtain an energy reduction measured at 80% while maintaining the original level of inference accuracy.\n",
      "\n",
      "\n",
      "Regarding the paper available at https://arxiv.org/pdf/2304.09695.pdf , answer the following question. Multiple options can be correct. Try to be as precise as you can, but it's ok to admit if you don't know.\n",
      "\n",
      "In the presented neural network, what can change during inference? Justify.\n",
      "(a) The network function composition or the selective activation of parts of the network.\n",
      "Between other things, this includes early-exits, conditional computing, and the cases where a recurrent neural net (e.g. RNN, LSTM, GRU) runs a variable number of steps.\n",
      "(b) Network weights are generated (except quantization).\n",
      "(c) Quantization (or change in precision) of weights or feature maps.\n",
      "(d) None of the above or not mentioned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 - 109\n",
    "absidx = 109\n",
    "# content = prompt.format(abstract=abstracts[absidx])\n",
    "content = prompt.format(url=urls[absidx])\n",
    "# print(urls[absidx])\n",
    "# print()\n",
    "print(titles[absidx])\n",
    "print()\n",
    "print(abstracts[absidx])\n",
    "print()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.error import APIConnectionError\n",
    "from time import sleep\n",
    "\n",
    "absidx = 10\n",
    "content = prompt.format(abstract=abstracts[absidx])\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": content}\n",
    "]\n",
    "retries = 4\n",
    "for _ in range(retries):\n",
    "  try:\n",
    "    ans = openai.ChatCompletion.create(\n",
    "      # model=\"gpt-3.5-turbo\",\n",
    "      model=\"gpt-3.5-turbo-0613\",\n",
    "      # model=\"gpt-4-0613\",\n",
    "      # prompt=prompt.format(abstract=abstracts[0]),\n",
    "      messages=messages,\n",
    "      # max_tokens=2048,\n",
    "      temperature=0.0,\n",
    "    )\n",
    "  except APIConnectionError:\n",
    "    print(\"Re-trying\")\n",
    "    sleep(3)\n",
    "    continue\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consider the following text:\n",
      "\"this paper investigates the energy savings that near-subthreshold processors can obtain in edge ai applications and proposes strategies to improve them while maintaining the accuracy of the application. the selected processors deploy adaptive voltage scaling techniques in which the frequency and voltage levels of the processor core are determined at the run-time. in these systems, embedded ram and flash memory size is typically limited to less than 1 megabyte to save power. this limited memory imposes restrictions on the complexity of the neural networks model that can be mapped to these devices and the required trade-offs between accuracy and battery life. to address these issues, we propose and evaluate alternative 'big-little' neural network strategies to improve battery life while maintaining prediction accuracy. the strategies are applied to a human activity recognition application selected as a demonstrator that shows that compared to the original network, the best configurations obtain an energy reduction measured at 80% while maintaining the original level of inference accuracy.\"\n",
      "\n",
      "Now answer the following question. Multiple options can be correct. Try to be as precise as you can, but it's ok\n",
      "to admit if you don't know.\n",
      "\n",
      "In the presented neural network, what can change if you give just test data samples? Justify.\n",
      "(a) The network function composition, topology, or architecture. This includes the cases where a recurrent neural net (e.g. RNN, LSTM, GRU) runs a variable number of steps.\n",
      "(b) The network weights (except quantization).\n",
      "(c) Quantization (or change in precision) of weights or feature maps.\n",
      "(d) None of the above or not mentioned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy-efficient and privacy-aware social distance monitoring with low-resolution infrared sensors and adaptive inference\n",
      "\n",
      "low-resolution infrared (ir) sensors combined with machine learning (ml) can be leveraged to implement privacy-preserving social distance monitoring solutions in indoor spaces. however, the need of executing these applications on internet of things (iot) edge nodes makes energy consumption critical. in this work, we propose an energy-efficient adaptive inference solution consisting of the cascade of a simple wake-up trigger and a 8-bit quantized convolutional neural network (cnn), which is only invoked for difficult-to-classify frames. deploying such adaptive system on a iot microcontroller, we show that, when processing the output of a 8x8 low-resolution ir sensor, we are able to reduce the energy consumption by 37-57% with respect to a static cnn-based approach, with an accuracy drop of less than 2% (83% balanced accuracy).\n",
      "\n",
      "(b) The network weights (except quantization).\n",
      "\n",
      "In the presented neural network, if only test data samples are given, the network weights can still change during the inference process. This is because the weights are adjusted based on the input data and the training process, which is not mentioned in the given text.\n"
     ]
    }
   ],
   "source": [
    "print(titles[absidx])\n",
    "print()\n",
    "print(abstracts[absidx])\n",
    "print()\n",
    "print(ans[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
